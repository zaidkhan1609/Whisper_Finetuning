# Whisper Fine-Tuning with LoRA (Production-Ready, Local Pipeline)

A **production-oriented Speech-to-Text (STT) system** built by fine-tuning **OpenAI Whisper-Medium** using **LoRA (Low-Rank Adaptation)** â€” implemented end-to-end with **native PyTorch**, **local data pipelines**, and **custom training/inference logic**.

This project deliberately avoids high-level â€œauto-magicâ€ abstractions in favor of **explicit control over data flow, tensor interfaces, and performance**.

---

## ğŸš€ Project Highlights

- ğŸ”§ **From-scratch pipeline**: Audio â†’ CSV manifests â†’ PyTorch training â†’ inference
- ğŸ™ï¸ **Whisper-Medium + LoRA** fine-tuning (parameter-efficient, GPU-friendly)
- âš™ï¸ **Pure PyTorch training loop** (no HF Trainer dependency in final version)
- ğŸ§  Handles real-world issues:
  - Encoder/decoder interface mismatches
  - AMP / CUDA edge cases
  - Custom collators & tensor shape alignment
- ğŸ’¾ **Local-first**: No cloud dependency, no HF datasets requirement
- ğŸ§ **MP3-ready inference** (auto-resampling handled)

---

## ğŸ“Š Training Results

| Metric | Value |
|------|------|
| Base Model | `openai/whisper-medium` |
| Fine-tuning Method | LoRA (PEFT) |
| Trainable Params | ~4.7M (~0.61%) |
| Initial Loss | ~0.33 |
| Final Loss | ~0.01 |
| Hardware | Single GPU (CUDA + AMP) |

Training was validated against **unseen audio samples**, achieving clean, accurate transcriptions on noisy, real-world speech.

---

## ğŸ—‚ï¸ Repository Structure

```text
.
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_lora.py        # Full training loop (PyTorch + AMP)
â”‚   â”œâ”€â”€ model.py             # Whisper + LoRA adapter loading
â”‚   â”œâ”€â”€ dataset.py           # Audio + text preprocessing
â”‚   â”œâ”€â”€ collator.py          # Custom batch collation
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ inference.py              # Batch inference (MP3/WAV supported)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/            # CSV manifests
â”‚   â””â”€â”€ test_audio/           # Sample inference audio
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ whisper-medium-lora/  # Trained LoRA adapters
â”‚
â””â”€â”€ README.md
