model:
  name: openai/whisper-medium
  language: english
  task: transcribe

lora:
  r: 16
  alpha: 32
  dropout: 0.1
  target_modules:
    - q_proj
    - v_proj

data:
  train_csv: data/processed/train.csv
  val_csv: data/processed/val.csv
  audio_column: audio_path
  text_column: sentence
  sample_rate: 16000
  max_train_samples: 2000
  max_val_samples: 200

training:
  output_dir: models/whisper-medium-lora
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  learning_rate: 1e-4
  num_train_epochs: 3
  fp16: true
  logging_steps: 50
  save_steps: 500
  warmup_steps: 300
